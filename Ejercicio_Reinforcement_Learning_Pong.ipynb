{"cells":[{"cell_type":"markdown","metadata":{"id":"Tyd5TzWyTTRL"},"source":["# Aprendizaje por Refuerzo: el Pong"]},{"cell_type":"markdown","metadata":{"id":"ZHGbnRCVTTRQ"},"source":["El artículo completo en el blog [Aprende Machine Learning](http://www.aprendemachinelearning.com) en Español.\n","\n","Crearemos el juego del pong con interface gráfica de Matplotlib"]},{"cell_type":"markdown","metadata":{"id":"tqiddBJMTTRR"},"source":["El Agente deberá aprender a jugar sólo mediante premios y castigos.\n","\n","Crearemos las clases:\n","\n","* Agente: implementará el algoritmo de QLearning\n","* Environment: será nuestro tablero de juego\n","\n","Y crearemos una función para comenzar a jugar, donde entrenará iterando miles de partidas de pong.\n","\n","Finalmente, ejecutarmos 1 partida con el agente ya entrenado\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:21:01.578976Z","start_time":"2020-12-27T10:20:58.063893Z"},"id":"jphKQdvHTTRS"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from random import randint\n","from time import sleep\n","from IPython.display import clear_output\n","from math import ceil,floor\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"GBszYWb5TTRU"},"source":["# Clase Agente"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:22:24.177788Z","start_time":"2020-12-27T10:22:24.158177Z"},"id":"tZq4USXzTTRV"},"outputs":[],"source":["class PongAgent:\n","    \n","    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n","\n","        # Creamos la tabla de politicas\n","        if policy is not None:\n","            self._q_table = policy\n","        else:\n","            position = list(game.positions_space.shape)\n","            position.append(len(game.action_space))\n","            self._q_table = np.zeros(position)\n","        \n","        self.discount_factor = discount_factor\n","        self.learning_rate = learning_rate\n","        self.ratio_explotacion = ratio_explotacion\n","\n","    def get_next_step(self, state, game):\n","        \n","        # Damos un paso aleatorio...\n","        next_step = np.random.choice(list(game.action_space))\n","        \n","        # o tomaremos el mejor paso...\n","        if np.random.uniform() <= self.ratio_explotacion:\n","            # tomar el maximo\n","            idx_action = np.random.choice(np.flatnonzero(\n","                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n","                ))\n","            next_step = list(game.action_space)[idx_action]\n","\n","        return next_step\n","\n","    # actualizamos las politicas con las recompensas obtenidas\n","    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n","        idx_action_taken =list(game.action_space).index(action_taken)\n","\n","        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n","        actual_q_value = actual_q_value_options[idx_action_taken]\n","\n","        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n","        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n","        if reached_end:\n","            future_max_q_value = reward_action_taken #maximum reward\n","\n","        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n","                                              self.learning_rate*(future_max_q_value -actual_q_value)\n","    \n","    def print_policy(self):\n","        for row in np.round(self._q_table,1):\n","            for column in row:\n","                print('[', end='')\n","                for value in column:\n","                    print(str(value).zfill(5), end=' ')\n","                print('] ', end='')\n","            print('')\n","            \n","    def get_policy(self):\n","        return self._q_table\n","    "]},{"cell_type":"markdown","metadata":{"id":"44lkVWVbTTRW"},"source":["# Clase Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:22:39.529477Z","start_time":"2020-12-27T10:22:39.493343Z"},"id":"OCPx45S0TTRX"},"outputs":[],"source":["class PongEnvironment:\n","    \n","    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n","        \n","        self.action_space = ['Arriba','Abajo']\n","        \n","        self._step_penalization = 0\n","        \n","        self.state = [0,0,0]\n","        \n","        self.total_reward = 0\n","        \n","        self.dx = movimiento_px\n","        self.dy = movimiento_px\n","        \n","        filas = ceil(height_px/movimiento_px)\n","        columnas = ceil(width_px/movimiento_px)\n","        \n","        self.positions_space = np.array([[[0 for z in range(columnas)] \n","                                                  for y in range(filas)] \n","                                                     for x in range(filas)])\n","\n","        self.lives = max_life\n","        self.max_life=max_life\n","        \n","        self.x = randint(int(width_px/2), width_px) \n","        self.y = randint(0, height_px-10)\n","        \n","        self.player_alto = int(height_px/4)\n","\n","        self.player1 = self.player_alto  # posic. inicial del player\n","        \n","        self.score = 0\n","        \n","        self.width_px = width_px\n","        self.height_px = height_px\n","        self.radio = 2.5\n","\n","    def reset(self):\n","        self.total_reward = 0\n","        self.state = [0,0,0]\n","        self.lives = self.max_life\n","        self.score = 0\n","        self.x = randint(int(self.width_px/2), self.width_px) \n","        self.y = randint(0, self.height_px-10)\n","        return self.state\n","\n","    def step(self, action, animate=False):\n","        self._apply_action(action, animate)\n","        done = self.lives <=0 # final\n","        reward = self.score\n","        reward += self._step_penalization\n","        self.total_reward += reward\n","        return self.state, reward , done\n","\n","    def _apply_action(self, action, animate=False):\n","        \n","        if action == \"Arriba\":\n","            self.player1 += abs(self.dy)\n","        elif action == \"Abajo\":\n","            self.player1 -= abs(self.dy)\n","            \n","        self.avanza_player()\n","\n","        self.avanza_frame()\n","\n","        if animate:\n","            clear_output(wait=True);\n","            fig = self.dibujar_frame()\n","            plt.show()\n","\n","        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n","    \n","    def detectaColision(self, ball_y, player_y):\n","        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n","            return True\n","        else:\n","            return False\n","    \n","    def avanza_player(self):\n","        if self.player1 + self.player_alto >= self.height_px:\n","            self.player1 = self.height_px - self.player_alto\n","        elif self.player1 <= -abs(self.dy):\n","            self.player1 = -abs(self.dy)\n","\n","    def avanza_frame(self):\n","        self.x += self.dx\n","        self.y += self.dy\n","        if self.x <= 3 or self.x > self.width_px:\n","            self.dx = -self.dx\n","            if self.x <= 3:\n","                ret = self.detectaColision(self.y, self.player1)\n","\n","                if ret:\n","                    self.score = 10\n","                else:\n","                    self.score = -10\n","                    self.lives -= 1\n","                    if self.lives>0:\n","                        self.x = randint(int(self.width_px/2), self.width_px)\n","                        self.y = randint(0, self.height_px-10)\n","                        self.dx = abs(self.dx)\n","                        self.dy = abs(self.dy)\n","        else:\n","            self.score = 0\n","\n","        if self.y < 0 or self.y > self.height_px:\n","            self.dy = -self.dy\n","\n","    def dibujar_frame(self):\n","        fig = plt.figure(figsize=(5, 4))\n","        a1 = plt.gca()\n","        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n","        a1.set_ylim(-5, self.height_px+5)\n","        a1.set_xlim(-5, self.width_px+5)\n","\n","        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n","        a1.add_patch(circle);\n","        a1.add_patch(rectangle)\n","        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n","        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n","        if self.lives <=0:\n","            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n","        elif self.total_reward >= 1000:\n","            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n","        return fig\n"]},{"cell_type":"markdown","metadata":{"id":"IccyH802TTRY"},"source":["# Juego"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:22:51.265359Z","start_time":"2020-12-27T10:22:51.249319Z"},"id":"Me1C64QJTTRZ"},"outputs":[],"source":["def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n","         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n","\n","    if game is None:\n","        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n","        # si usamos movimiento_px = 3 la tabla sera de 14x17\n","        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n","        \n","    if learner is None:\n","        print(\"Begin new Train!\")\n","        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n","\n","    max_points= -9999\n","    first_max_reached = 0\n","    total_rw=0\n","    steps=[]\n","\n","    for played_games in range(0, rounds):\n","        state = game.reset()\n","        reward, done = None, None\n","        \n","        itera=0\n","        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n","            old_state = np.array(state)\n","            next_action = learner.get_next_step(state, game)\n","            state, reward, done = game.step(next_action, animate=animate)\n","            if rounds > 1:\n","                learner.update(game, old_state, next_action, reward, state, done)\n","            itera+=1\n","        \n","        steps.append(itera)\n","        \n","        total_rw+=game.total_reward\n","        if game.total_reward > max_points:\n","            max_points=game.total_reward\n","            first_max_reached = played_games\n","        \n","        if played_games %500==0 and played_games >1 and not animate:\n","            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n","                \n","    if played_games>1:\n","        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n","        \n","    #learner.print_policy()\n","    \n","    return learner, game\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:24:06.516334Z","start_time":"2020-12-27T10:22:51.808220Z"},"id":"Z2-zuWuBTTRZ","outputId":"6e2d8b06-dd1b-4c6f-b438-24baa0fbaabe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639005747813,"user_tz":240,"elapsed":132268,"user":{"displayName":"CRISTHIAN CONDE AJURURO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08638481017740176508"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Begin new Train!\n","-- Partidas[ 500 ] Avg.Puntos[ 23 ]  AVG Steps[ 248 ] Max Score[ 150 ]\n","-- Partidas[ 1000 ] Avg.Puntos[ 27 ]  AVG Steps[ 263 ] Max Score[ 150 ]\n","-- Partidas[ 1500 ] Avg.Puntos[ 29 ]  AVG Steps[ 271 ] Max Score[ 240 ]\n","-- Partidas[ 2000 ] Avg.Puntos[ 30 ]  AVG Steps[ 272 ] Max Score[ 240 ]\n","-- Partidas[ 2500 ] Avg.Puntos[ 31 ]  AVG Steps[ 277 ] Max Score[ 240 ]\n","-- Partidas[ 3000 ] Avg.Puntos[ 33 ]  AVG Steps[ 284 ] Max Score[ 270 ]\n","-- Partidas[ 3500 ] Avg.Puntos[ 35 ]  AVG Steps[ 288 ] Max Score[ 270 ]\n","-- Partidas[ 4000 ] Avg.Puntos[ 37 ]  AVG Steps[ 295 ] Max Score[ 360 ]\n","-- Partidas[ 4500 ] Avg.Puntos[ 38 ]  AVG Steps[ 299 ] Max Score[ 360 ]\n","-- Partidas[ 5000 ] Avg.Puntos[ 39 ]  AVG Steps[ 305 ] Max Score[ 370 ]\n","-- Partidas[ 5500 ] Avg.Puntos[ 40 ]  AVG Steps[ 309 ] Max Score[ 510 ]\n","Partidas[ 5999 ] Avg.Puntos[ 42 ] Max score[ 510 ] en partida[ 5085 ]\n"]}],"source":["learner, game = play(rounds=6000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-12-27T10:35:16.554658Z","start_time":"2020-12-27T10:25:44.533659Z"},"id":"P_VDpZOMTTRa","outputId":"9d7a6f9d-de6b-4cb9-b79e-810ef7d626d7","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1639006325758,"user_tz":240,"elapsed":454975,"user":{"displayName":"CRISTHIAN CONDE AJURURO","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08638481017740176508"}}},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["learner2 = PongAgent(game, policy=learner.get_policy())\n","learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n","player = play(rounds=1, learner=learner2, game=game, animate=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1kzUh_XTTRa"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oV0D-Y-hTTRb"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBVa-W4OTTRb"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"Copia de Ejercicio_Reinforcement_Learning_Pong.ipynb","provenance":[{"file_id":"https://github.com/jbagnato/machine-learning/blob/master/Ejercicio_Reinforcement_Learning_Pong.ipynb","timestamp":1639005300204}]}},"nbformat":4,"nbformat_minor":0}